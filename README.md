LLM-Based Research Assistant Application

This project is a research assistant application that allows users to upload research papers (PDF or text) and interact with them through semantic search and summarization. The system uses Retrieval-Augmented Generation (RAG) with large language models to provide context-aware answers and structured summaries.

Features: 

* Upload and process PDF or text documents
* Semantic search implemented with LangChain and FAISS
* Context-aware answers generated using OpenAI language models
* Structured summarization of research papers (Background, Method, Results, Limitations)
* Web interface built with Streamlit and deployed on Streamlit Cloud

Tech Stack: 

* Python 3.9+
* Streamlit – web interface and deployment
* LangChain – RAG pipeline
* FAISS – vector search for embeddings
* OpenAI API – large language model integration
* PyPDF – document parsing
